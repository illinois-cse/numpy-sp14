{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Version:  Python 2.7"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import this"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scientific Python for Engineers"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Floating-Point Numbers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook discusses the main features of [Numerical Python](http://www.numpy.org/) (`numpy`), [Scientific Python](http://www.scipy.org/) (`scipy`), and their relatives in an engineering context.\n",
      "\n",
      "Although any installation of [IPython](http://ipython.org/) will work with a version of this notebook, we recommend that you download and install the [Enthought Canopy Distribution](https://www.enthought.com/products/canopy/) of Python, which is free for academic users.  To launch the notebook, open a command terminal, type `ipython notebook tutorial.ipynb`, and press Return.\n",
      "\n",
      "A few notes on this tutorial:\n",
      "\n",
      "- Check the top left corner of this page for the Python version this notebook is supposed to work with.  Enthought Canopy uses Python 2.7.x, so if you are using that version, you will need the 2.7 version of this notebook.  There is also a 3.3 version, which requires some small adjustments if you are familiar with Python 2.7.  Python 3 represents the future of Python and is a better platform for those developing new codes (rather than developing existing scripts).  Most major modules are available in both flavors now.\n",
      "\n",
      "- Early on, we will incidentally utilize features of packages not yet introduced (such as `matplotlib`).  Rest assured that the major features of these modules will be explicitly discussed at some point if it is not clear now.\n",
      "\n",
      "- Code blocks starting with `$` are intended to be run on the command line, not executed as Python code."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Standard Header"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we will be utilizing a number of packages with reasonably long names, we will adopt the _de facto_ standard module abbreviations in the following header.  We also ensure that our [division behavior is sensible](http://www.python.org/dev/peps/pep-0238/) by importing from `__future__`:  _i.e._, promotion to `double` will occur from `int` or `long` data types involving division:  `1/2 == 0.5`.  Although this is the default in Python 3, it is a trivial way to help this notebook work in Python 2 if that's what you are using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#IPython magic command for inline plotting\n",
      "%matplotlib inline\n",
      "#a better plot shape for IPython\n",
      "mpl.rcParams['figure.figsize']=[15,3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Floating-point mathematics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Floating-point mathematics allows the representation of numbers too large to fit into memory well as integers, as well as with fractional parts.  Modern floating-point arithmetic typically allows the representation of numbers as 32-bit `float`s or 64-bit `double`s.\n",
      "\n",
      "This task is achieved by splitting the bytes up into a sign bit, an binary exponent, and a binary mantissa or significand.  (Consult the figure below.)\n",
      "\n",
      "* The sign bit tells you if the number is positive (`0`) or negative (`1`).\n",
      "* The exponent is counted from a negative value at half the range in order to also represent small numbers.\n",
      "* The mantissa includes an implied leading bit, because you don't write $0.1\\times 10^{-2}$ but $1\\times 10^{-3}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(filename='floating-point.png', width=800, embed=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Calculate the binary representation of $1.1$, $0.8$, and $0.3$ using [this calculator](http://babbage.cs.qc.edu/IEEE-754/).  Compare $0.3$ to the result of $1.1-0.8$ (compare the `double` floating-point type)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.1-0.8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes the result of a calculation will _overflow_ (be larger than representable) or _underflow_ (be smaller than representable).  In these cases, you need to use a larger data type (`double` instead of `float`, frequently).  Alternatively, if extremely high precision is required, you can use an extended arithmetic library such as `mpmath` (below), although this is uncommon.\n",
      "\n",
      "Some special types exist as well:  $+\\infty$ `Inf`, $-\\infty$ `-Inf`, and `NaN` (Not a Number).  This occur as the result of procedures with undefined results (such as division by zero) and allow you to systematically handle errors and bugs as they arise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python lets you see the effective range and minimum representable value (`epsilon`, the smallest value distinguishable from zero by the machine)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Standard floating-point variables are limited by their representation in bits.\n",
      "import sys\n",
      "print sys.float_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(From this, incidentally, you can tell that Python uses `double` as the basic floating-point type.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For more details, consult [Finley, 2000](http://tfinley.net/notes/cps104/floating.html) (from whom the example was borrowed) and [IEEE-754 Analysis](http://babbage.cs.qc.edu/IEEE-754/), a calculator which shows you the pieces of the representation for `float`, `double`, and `quad128` types. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extended arithmetic:  `mpmath`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes you need more accuracy than you can carry in 64 bits.\n",
      "\n",
      "The [`mpmath`](http://sage.math.washington.edu/home/fredrik/mpmath/doc/0.18/) module provides two extremely valuable features:  arbitrary-precision floating-point mathematics and interval arithmetic.  Since it supports much higher resolution than conventional double-precision floating-point numbers, `mpmath` also provides transcendental functions to work with these higher-precision representations.\n",
      "\n",
      "(Python 3 supports `long` integers as the default type, which have [unlimited precision for integral values](http://docs.python.org/3/library/stdtypes.html#typesnumeric).)\n",
      "\n",
      "_N.B._:  The `mpmath` module is not likely installed on your machine previous to encountering it here.  If you are using Canopy and have a non-Basic license, you can install it with the package manager and then run the `import mpmath` commands below again."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Arbitrary-Precision Arithmetic"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Arbitrary-precision arithmetic](https://en.wikipedia.org/wiki/Arbitrary_precision_arithmetic) refers to calculations with numbers whose precision is only limited by the physical capacity of memory.  This can avoid overflow and underflow of floating-point numbers, but is relatively slow compared to classical floating-point calculations (which can be implemented in hardware)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mpmath\n",
      "from mpmath import mp\n",
      "\n",
      "#mp is the object containing the state information for the module.  The two main variables\n",
      "#we are interested in are related and each updates in response to the other.\n",
      "#   prec - (binary) precision of output\n",
      "#   dps - decimal places\n",
      "print(mp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.pi)\n",
      "mp.dps = 15\n",
      "print(mpmath.mpf(np.pi))\n",
      "mp.dps = 32\n",
      "print(mpmath.mpf(np.pi))\n",
      "mp.dps = 100\n",
      "print(mpmath.mpf(np.pi)) #exhausts the accuracy of double-precision floating-point numbers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Why are these different?\n",
      "print(mpmath.mpf(2.0 ** 0.5))\n",
      "print(mpmath.mpf(2.0) ** mpmath.mpf(0.5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is better to put the definition as a string, since the accuracy of the `mpf` function is limited by the accuracy of the input."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(mpmath.mpf(0.3))\n",
      "print(mpmath.mpf('0.3'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, `mpmath` provides [transcendental functions](http://sage.math.washington.edu/home/fredrik/mpmath/doc/0.18/functions/index.html) for working with these arbitrary-precision values.  [Plotting functions](http://sage.math.washington.edu/home/fredrik/mpmath/doc/0.18/plotting.html) are also available (but they can take a while depending on your precision)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mp.dps = 50\n",
      "print(mpmath.besselj(1.0,1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mpmath.cplot(lambda z: mpmath.besselj(1,z), [-8,8], [-8,8], points=50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r, R = 1, 2.5\n",
      "f = lambda u, v: [r*mpmath.cos(u), (R+r*mpmath.sin(u))*mpmath.cos(v), (R+r*mpmath.sin(u))*mpmath.sin(v)]\n",
      "mpl.rcParams['figure.figsize']=[6,6]\n",
      "mpmath.splot(f, [0, 2*mpmath.pi], [0, 2*mpmath.pi])\n",
      "mpl.rcParams['figure.figsize']=[15,3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interval Arithmetic"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Interval arithmetic](https://en.wikipedia.org/wiki/Interval_arithmetic) ([iv](http://sage.math.washington.edu/home/fredrik/mpmath/doc/0.18/contexts.html#arbitrary-precision-interval-arithmetic-iv)) has been developed to track the bounds of rounding and measurement errors by propagating a range forward through the calculations.\n",
      "\n",
      "This does not yield identical results to [classical error propagation formulae](https://en.wikipedia.org/wiki/Propagation_of_uncertainty), however, which derive from arithmetic on probability distributions (Lugo, 2012).  In general, interval arithmetic provides pessimistic results since it does not take into account distributions, only bounds.  It can be much more straightforward to implement, though, depending on how complex the equations are for which errors are to be calculated."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpmath import iv\n",
      "iv.dps = 15\n",
      "iv.pretty = True\n",
      "\n",
      "#Body mass index calculation\n",
      "m = iv.mpf(['79.5', '80.5'])\n",
      "h = iv.mpf(['1.795', '1.805'])\n",
      "bmi = m/h**2\n",
      "print('The weight range is %s kg.'%m)\n",
      "print('This corresponds to a BMI range of %s for a %s m tall person.'%(bmi, h))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Error propagation for resistance measurement using interval arithmetic.\n",
      "#We measure voltage V\u00b1\u03c3V and current I\u00b1\u03c3I, leading to the following intervals.\n",
      "V_obs = 9 #V\n",
      "sigma_V = 0.6 #V\n",
      "voltage = iv.mpf([V_obs-sigma_V, V_obs+sigma_V])\n",
      "\n",
      "I_obs = 0.5 #A\n",
      "sigma_I = 0.01 * I_obs #A\n",
      "current = iv.mpf([I_obs-sigma_I, I_obs+sigma_I])\n",
      "\n",
      "resistance = voltage / current\n",
      "print(u'Interval arithmetic yields a result of %s \u03a9.'%resistance)\n",
      "\n",
      "#For comparison, this is the classical error propagation result\u2014which requires a lot more footwork on your end but has tighter bounds.\n",
      "sigma_R = (sigma_V**2 * I_obs **-2 + sigma_I**2 * (-V_obs/I_obs**2)**2) ** 0.5\n",
      "res_ep_lo = V_obs/I_obs - sigma_R\n",
      "res_ep_hi = V_obs/I_obs + sigma_R\n",
      "print(u'The classical error propagation method yields [%f, %f] \u03a9.'%(res_ep_lo, res_ep_hi))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Additionally, `mpmath` supports some convenient utilities such as [automatic constant recognition](http://sage.math.washington.edu/home/fredrik/mpmath/doc/0.18/identification.html#constant-recognition) and [plotting of interval values](http://sage.math.washington.edu/home/fredrik/mpmath/doc/0.18/plotting.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Finding Numerical Error"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recollect the Zen of Python (`import this`):  \"In the face of ambiguity, refuse the temptation to guess.\"\n",
      "\n",
      "You have certainly encountered errors previously in working with Python.  There exist a number of approaches (collectively 'debugging') which serve to root out many of these errors and to make the others tractable.\n",
      "\n",
      "In this section, we will discuss how you may be able to find out if numerical errors are haunting you.  Optimization is treated elsewhere.\n",
      "\n",
      "Also, this doesn't address _mathematical_ errors, like when you mistype an equation, but when \n",
      "\n",
      "In the first place, it is good to use characteristic scales such that _most_ of your expected values lie within the range $[10^3-10^{-3}]$.  This allows you to easily identify underflow and overflow errors, as well as gross oscillations and instabilities."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Langtangen, Hans Petter.  _Python Scripting for Computational Science_, 3ed.  Berlin\u2013Heidelberg:  Springer\u2013Verlag, 2009.\n",
      "- Lugo, Michael.  [On propagation of errors](http://gottwurfelt.com/2012/03/26/on-propagation-of-errors/).  26 March 2012.\n",
      "- Warren, Russell.  [A Brief Intro to Profiling in Python](https://speakerdeck.com/rwarren/a-brief-intro-to-profiling-in-python).  Ottawa Python Authors Group, 28 February 2013."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Neal Davis developed these materials for [Computational Science and Engineering](http://cse.illinois.edu/) at the University of Illinois at Urbana\u2013Champaign.  This content is available under a Creative Commons Attribution 3.0 Unported License."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}